{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from scipy import stats\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPP_path = r'C:\\Users\\felip\\Desktop\\Electricity\\Energy Market\\Energy Market (SPP)'\n",
    "\n",
    "def add_info(df):\n",
    "    intervals = df[df.columns[0]].values.tolist()\n",
    "    dates = []\n",
    "    times = []\n",
    "    weekday = []\n",
    "    months = []\n",
    "    days = []\n",
    "    hour = []\n",
    "    minute_of_day = []\n",
    "    for interval in intervals:\n",
    "        date = interval.split(' ')[0]\n",
    "        try:\n",
    "            date = dt.datetime.strptime(date,'%Y-%m-%d').date()\n",
    "        except:\n",
    "            date = dt.datetime.strptime(date,'%m/%d/%Y').date()            \n",
    "        dates.append(date)\n",
    "        months.append(date.month)\n",
    "        days.append(date.day)\n",
    "        if date.weekday() < 5:\n",
    "            weekday.append(True)\n",
    "        else:\n",
    "            weekday.append(False)\n",
    "        time = interval.split(' ')[1].split('.')[0]\n",
    "        time = dt.datetime.strptime(time,'%H:%M:%S').time()\n",
    "        times.append(time)\n",
    "        hour.append(dt.time(time.hour))\n",
    "        minute_of_day.append(60*time.hour+time.minute)\n",
    "    df['Local Date'] = np.array(dates)\n",
    "    df['Local Time'] = np.array(times)\n",
    "    df['Hour'] = np.array(hour)\n",
    "    df['Weekday'] = np.array(weekday)\n",
    "    df['Month'] = np.array(months)\n",
    "    df['Day'] = np.array(days)\n",
    "    df['Minute of Day'] = np.array(minute_of_day)\n",
    "    return df\n",
    "\n",
    "def GMT2CT(s):\n",
    "    date = s.split('T')[0]\n",
    "    date = dt.datetime.strptime(date,'%Y-%m-%d').date()\n",
    "    time = s.split('T')[1][:-1]\n",
    "    hour = int(time.split(':')[0])\n",
    "    if hour >= 6:\n",
    "        hour = hour - 6\n",
    "    else:\n",
    "        hour = 24 + (hour - 6)\n",
    "        date = date - timedelta(1)\n",
    "    time = str(hour) + ':' + time.split(':')[1] + ':' + time.split(':')[2]\n",
    "    time = dt.datetime.strptime(time,'%H:%M:%S').time()\n",
    "    return [date, time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_mix_2018 = pd.read_csv(SPP_path + '\\Generation Mix By Fuel Type\\GenMix_2018.csv')\n",
    "list_intervals = gen_mix_2018[gen_mix_2018.columns[0]].values.tolist()\n",
    "local_time = []\n",
    "local_date = []\n",
    "for value in list_intervals:\n",
    "    local_date.append(GMT2CT(value)[0])\n",
    "    local_time.append(GMT2CT(value)[1])\n",
    "gen_mix_2018['Local Date'] = np.array(local_date)\n",
    "gen_mix_2018['Local Time'] = np.array(local_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_31 = []\n",
    "for n in range(1,10):\n",
    "    days_31.append('0'+str(n))\n",
    "for n in range(10,32):\n",
    "    days_31.append(str(n))\n",
    "cal_dict = {'01':days_31,\n",
    "            '02':days_31[0:28],\n",
    "            '03':days_31,\n",
    "           '04':days_31[0:-1],\n",
    "            '05':days_31,\n",
    "            '06':days_31[0:-1],\n",
    "           '07':days_31,\n",
    "            '08':days_31,\n",
    "            '09':days_31[0:-1],\n",
    "           '10':days_31,\n",
    "           '11':days_31[0:-1],\n",
    "           '12':days_31}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening and concatenating RT datasets\n",
    "path = r'C:\\Users\\felip\\Desktop\\Electricity\\Energy Market\\Energy Market (SPP)\\RT\\2018'\n",
    "RT_path = 'RTBM-LMP-DAILY-SL-2018'\n",
    "end = '.csv'\n",
    "dfs = []\n",
    "for key in cal_dict.keys():\n",
    "    for value in cal_dict[key]:\n",
    "        dfs.append(pd.read_csv(path+'\\\\'+key+'\\\\By_Day\\\\'+RT_path+key+value+end))\n",
    "RT = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>LMP</th>\n",
       "      <th>Local Date</th>\n",
       "      <th>Local Time</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Minute of Day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interval</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/01/2018 00:05:00</th>\n",
       "      <td>01/01/2018 00:05:00</td>\n",
       "      <td>246.567610</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>00:05:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 00:10:00</th>\n",
       "      <td>01/01/2018 00:10:00</td>\n",
       "      <td>64.864068</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>00:10:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 00:15:00</th>\n",
       "      <td>01/01/2018 00:15:00</td>\n",
       "      <td>164.686048</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 00:20:00</th>\n",
       "      <td>01/01/2018 00:20:00</td>\n",
       "      <td>173.867912</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 00:25:00</th>\n",
       "      <td>01/01/2018 00:25:00</td>\n",
       "      <td>163.353003</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>00:25:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Interval         LMP  Local Date Local Time  \\\n",
       "Interval                                                                      \n",
       "01/01/2018 00:05:00  01/01/2018 00:05:00  246.567610  2018-01-01   00:05:00   \n",
       "01/01/2018 00:10:00  01/01/2018 00:10:00   64.864068  2018-01-01   00:10:00   \n",
       "01/01/2018 00:15:00  01/01/2018 00:15:00  164.686048  2018-01-01   00:15:00   \n",
       "01/01/2018 00:20:00  01/01/2018 00:20:00  173.867912  2018-01-01   00:20:00   \n",
       "01/01/2018 00:25:00  01/01/2018 00:25:00  163.353003  2018-01-01   00:25:00   \n",
       "\n",
       "                         Hour  Weekday  Month  Day  Minute of Day  \n",
       "Interval                                                           \n",
       "01/01/2018 00:05:00  00:00:00     True      1    1              5  \n",
       "01/01/2018 00:10:00  00:00:00     True      1    1             10  \n",
       "01/01/2018 00:15:00  00:00:00     True      1    1             15  \n",
       "01/01/2018 00:20:00  00:00:00     True      1    1             20  \n",
       "01/01/2018 00:25:00  00:00:00     True      1    1             25  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregating settlement location for system-wide data\n",
    "RT2018_aggloc = RT.groupby('Interval')[['Interval',' LMP']].agg({'Interval':'first',\n",
    "                                                                    ' LMP':'mean'})\n",
    "RT2018 = add_info(RT2018_aggloc)\n",
    "RT2018 = RT2018.rename(columns={' LMP':'LMP'})\n",
    "RT2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening and concatenating DA datasets\n",
    "path = r'C:\\Users\\felip\\Desktop\\Electricity\\Energy Market\\Energy Market (SPP)\\DA\\2018'\n",
    "DA_path = 'DA-LMP-SL-2018'\n",
    "end = '0100.csv'\n",
    "dfs = []\n",
    "for key in cal_dict.keys():\n",
    "    for value in cal_dict[key]:\n",
    "        dfs.append(pd.read_csv(path+'\\\\'+key+'\\\\By_Day\\\\'+DA_path+key+value+end))\n",
    "DA2018 = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>LMP</th>\n",
       "      <th>Local Date</th>\n",
       "      <th>Local Time</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Minute of Day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interval</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/01/2018 01:00:00</th>\n",
       "      <td>01/01/2018 01:00:00</td>\n",
       "      <td>37.390157</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 02:00:00</th>\n",
       "      <td>01/01/2018 02:00:00</td>\n",
       "      <td>37.249877</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 03:00:00</th>\n",
       "      <td>01/01/2018 03:00:00</td>\n",
       "      <td>37.998882</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 04:00:00</th>\n",
       "      <td>01/01/2018 04:00:00</td>\n",
       "      <td>40.778408</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 05:00:00</th>\n",
       "      <td>01/01/2018 05:00:00</td>\n",
       "      <td>42.051515</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Interval        LMP  Local Date Local Time  \\\n",
       "Interval                                                                     \n",
       "01/01/2018 01:00:00  01/01/2018 01:00:00  37.390157  2018-01-01   01:00:00   \n",
       "01/01/2018 02:00:00  01/01/2018 02:00:00  37.249877  2018-01-01   02:00:00   \n",
       "01/01/2018 03:00:00  01/01/2018 03:00:00  37.998882  2018-01-01   03:00:00   \n",
       "01/01/2018 04:00:00  01/01/2018 04:00:00  40.778408  2018-01-01   04:00:00   \n",
       "01/01/2018 05:00:00  01/01/2018 05:00:00  42.051515  2018-01-01   05:00:00   \n",
       "\n",
       "                         Hour  Weekday  Month  Day  Minute of Day  \n",
       "Interval                                                           \n",
       "01/01/2018 01:00:00  01:00:00     True      1    1             60  \n",
       "01/01/2018 02:00:00  02:00:00     True      1    1            120  \n",
       "01/01/2018 03:00:00  03:00:00     True      1    1            180  \n",
       "01/01/2018 04:00:00  04:00:00     True      1    1            240  \n",
       "01/01/2018 05:00:00  05:00:00     True      1    1            300  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregating settlement location for system-wide data\n",
    "DA2018_aggloc = DA2018.groupby('Interval')[['Interval','LMP']].agg({'Interval':'first',\n",
    "                                                                    'LMP':'mean'})\n",
    "DA2018_aggloc = add_info(DA2018_aggloc)\n",
    "DA2018_aggloc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssr(prediction, test):\n",
    "    return ((prediction - test)**2).sum()\n",
    "def pe(prediction, test):\n",
    "    return (abs((prediction - test)/test))*100\n",
    "def filler(df, DA):\n",
    "    price_list = df[DA].values.tolist()\n",
    "    value = 0.0\n",
    "    new_list = []\n",
    "    for price in price_list:\n",
    "        if math.isnan(price)==True:\n",
    "            new_list.append(value)\n",
    "        else:\n",
    "            value = price\n",
    "            new_list.append(price)\n",
    "    df[DA] = np.array(new_list)\n",
    "    return df\n",
    "def means_dict(d):\n",
    "    means_d = {}\n",
    "    for key in d.keys():\n",
    "        means_d[key] = np.nanmean(np.array(d[key]))\n",
    "    return means_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging RT, DA and Load data\n",
    "comparison = DA2018_aggloc.iloc[:,0:2].join(RT2018,how='right',lsuffix='_DA',rsuffix='_RT')\n",
    "DART2018_5min = filler(comparison, 'LMP_DA')\n",
    "gen_2018 = gen_mix_2018\n",
    "new_index = []\n",
    "for i in range(gen_2018.shape[0]):\n",
    "    new_index.append(gen_2018['Local Date'].iloc[i].strftime(\"%m/%d/%Y\") + ' ' + gen_2018['Local Time'].iloc[i].strftime(\"%H:%M:%S\"))\n",
    "gen_2018.index = np.array(new_index)\n",
    "DART_gen_2018 = gen_2018.join(DART2018_5min,how='right',lsuffix='_gen',rsuffix='_price')\n",
    "DART_gen_2018 = DART_gen_2018.rename(columns={' Average Actual Load':'Load',\n",
    "                                             ' Wind Self':'Wind',\n",
    "                                             ' Coal Market':'Coal_Mkt',\n",
    "                                             ' Coal Self':'Coal_Self',\n",
    "                                             'Local Time_price':'Local Time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_clusters_2(train_df, depth, plot):\n",
    "    # converting datetime to int\n",
    "    minutes = []\n",
    "    for time in train_df.index:\n",
    "        minutes.append(time.hour * 60 + time.minute)\n",
    "    train_df['minutes'] = np.array(minutes)\n",
    "    X = train_df['minutes'].values.reshape(-1,1)\n",
    "    y = train_df['LMP_RT']\n",
    "    # Fit regression model\n",
    "    regr_1 = DecisionTreeRegressor(max_depth=depth)\n",
    "    regr_1.fit(X, y)\n",
    "    # Predict\n",
    "    X_test = train_df['minutes'].values.reshape(-1,1)\n",
    "    y_1 = regr_1.predict(X_test)\n",
    "    train_df['sklearn cluster'] = y_1\n",
    "    price_leaves = []\n",
    "    for price in y_1:\n",
    "        if price not in price_leaves:\n",
    "            price_leaves.append(price)\n",
    "    branch_dfs = []\n",
    "    for price in price_leaves:\n",
    "        branch_dfs.append(train_df[train_df['sklearn cluster']==price])\n",
    "    if plot == True:\n",
    "        plt.plot(X_test, y_1, color=\"cornflowerblue\",label=\"max_depth=\"+str(depth), linewidth=2)\n",
    "        plt.legend()\n",
    "    return branch_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening and concatenating DA Load datasets\n",
    "path = r'C:\\Users\\felip\\Desktop\\Electricity\\Energy Market\\Energy Market (SPP)\\DA Load\\2018'\n",
    "DA_path = 'DA-MC-2018'\n",
    "end = '0100.csv'\n",
    "dfs = []\n",
    "for key in cal_dict.keys():\n",
    "    for value in cal_dict[key]:\n",
    "        dfs.append(pd.read_csv(path+'\\\\'+key+'\\\\'+DA_path+key+value+end))\n",
    "DA_load_2018 = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Forecast Load to dataset\n",
    "DA_load_2018.index = DA_load_2018['Interval']\n",
    "comparison = DA_load_2018.iloc[:,8:9].join(DART_gen_2018,how='right')\n",
    "DART2018 = filler(comparison, ' Total Demand')\n",
    "DART2018 = DART2018.iloc[11:,:]\n",
    "DART2018 = DART2018.rename(columns={' Total Demand':'DA Load'})\n",
    "DART2018['Load_Diff'] = DART2018['Load'] - DART2018['DA Load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felip\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\felip\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\felip\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\felip\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA Load</th>\n",
       "      <th>GMT MKT Interval</th>\n",
       "      <th>Coal_Mkt</th>\n",
       "      <th>Coal_Self</th>\n",
       "      <th>Diesel Fuel Oil Market</th>\n",
       "      <th>Diesel Fuel Oil Self</th>\n",
       "      <th>Hydro Market</th>\n",
       "      <th>Hydro Self</th>\n",
       "      <th>Natural Gas Market</th>\n",
       "      <th>Gas Self</th>\n",
       "      <th>...</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Minute of Day</th>\n",
       "      <th>Load_Diff</th>\n",
       "      <th>Previous_Load_Diff</th>\n",
       "      <th>Previous_RT</th>\n",
       "      <th>Previous_RT_2</th>\n",
       "      <th>Previous_Load_Diff_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interval</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/01/2018 01:20:00</th>\n",
       "      <td>36085.6</td>\n",
       "      <td>2018-01-01T07:20:00Z</td>\n",
       "      <td>2991.5</td>\n",
       "      <td>18157.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.7</td>\n",
       "      <td>486.7</td>\n",
       "      <td>6054.3</td>\n",
       "      <td>2961.2</td>\n",
       "      <td>...</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>4.404</td>\n",
       "      <td>24.118414</td>\n",
       "      <td>27.302014</td>\n",
       "      <td>18.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 01:25:00</th>\n",
       "      <td>36085.6</td>\n",
       "      <td>2018-01-01T07:25:00Z</td>\n",
       "      <td>3000.8</td>\n",
       "      <td>18190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.8</td>\n",
       "      <td>486.1</td>\n",
       "      <td>6031.1</td>\n",
       "      <td>2948.6</td>\n",
       "      <td>...</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>21.518</td>\n",
       "      <td>-0.286</td>\n",
       "      <td>24.729624</td>\n",
       "      <td>26.031712</td>\n",
       "      <td>8.197667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 01:30:00</th>\n",
       "      <td>36085.6</td>\n",
       "      <td>2018-01-01T07:30:00Z</td>\n",
       "      <td>3003.2</td>\n",
       "      <td>18246.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>486.4</td>\n",
       "      <td>6089.9</td>\n",
       "      <td>2958.0</td>\n",
       "      <td>...</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>-8.024</td>\n",
       "      <td>21.518</td>\n",
       "      <td>28.389152</td>\n",
       "      <td>25.745730</td>\n",
       "      <td>8.545333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 01:35:00</th>\n",
       "      <td>36085.6</td>\n",
       "      <td>2018-01-01T07:35:00Z</td>\n",
       "      <td>3004.7</td>\n",
       "      <td>18273.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>486.0</td>\n",
       "      <td>6142.3</td>\n",
       "      <td>2938.2</td>\n",
       "      <td>...</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>-36.888</td>\n",
       "      <td>-8.024</td>\n",
       "      <td>28.267911</td>\n",
       "      <td>27.128896</td>\n",
       "      <td>4.402667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 01:40:00</th>\n",
       "      <td>36085.6</td>\n",
       "      <td>2018-01-01T07:40:00Z</td>\n",
       "      <td>3008.3</td>\n",
       "      <td>18229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.9</td>\n",
       "      <td>486.9</td>\n",
       "      <td>6171.6</td>\n",
       "      <td>2894.4</td>\n",
       "      <td>...</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>-102.888</td>\n",
       "      <td>-36.888</td>\n",
       "      <td>32.869229</td>\n",
       "      <td>29.842097</td>\n",
       "      <td>-7.798000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DA Load      GMT MKT Interval  Coal_Mkt  Coal_Self  \\\n",
       "Interval                                                                  \n",
       "01/01/2018 01:20:00  36085.6  2018-01-01T07:20:00Z    2991.5    18157.5   \n",
       "01/01/2018 01:25:00  36085.6  2018-01-01T07:25:00Z    3000.8    18190.0   \n",
       "01/01/2018 01:30:00  36085.6  2018-01-01T07:30:00Z    3003.2    18246.4   \n",
       "01/01/2018 01:35:00  36085.6  2018-01-01T07:35:00Z    3004.7    18273.8   \n",
       "01/01/2018 01:40:00  36085.6  2018-01-01T07:40:00Z    3008.3    18229.0   \n",
       "\n",
       "                      Diesel Fuel Oil Market   Diesel Fuel Oil Self  \\\n",
       "Interval                                                              \n",
       "01/01/2018 01:20:00                      0.0                    0.0   \n",
       "01/01/2018 01:25:00                      0.0                    0.0   \n",
       "01/01/2018 01:30:00                      0.0                    0.0   \n",
       "01/01/2018 01:35:00                      0.0                    0.0   \n",
       "01/01/2018 01:40:00                      0.0                    0.0   \n",
       "\n",
       "                      Hydro Market   Hydro Self   Natural Gas Market  \\\n",
       "Interval                                                               \n",
       "01/01/2018 01:20:00           43.7        486.7               6054.3   \n",
       "01/01/2018 01:25:00           43.8        486.1               6031.1   \n",
       "01/01/2018 01:30:00           43.5        486.4               6089.9   \n",
       "01/01/2018 01:35:00           43.1        486.0               6142.3   \n",
       "01/01/2018 01:40:00           43.9        486.9               6171.6   \n",
       "\n",
       "                      Gas Self          ...               Hour  Weekday  \\\n",
       "Interval                                ...                               \n",
       "01/01/2018 01:20:00     2961.2          ...           01:00:00     True   \n",
       "01/01/2018 01:25:00     2948.6          ...           01:00:00     True   \n",
       "01/01/2018 01:30:00     2958.0          ...           01:00:00     True   \n",
       "01/01/2018 01:35:00     2938.2          ...           01:00:00     True   \n",
       "01/01/2018 01:40:00     2894.4          ...           01:00:00     True   \n",
       "\n",
       "                     Month  Day  Minute of Day  Load_Diff  Previous_Load_Diff  \\\n",
       "Interval                                                                        \n",
       "01/01/2018 01:20:00      1    1             80     -0.286               4.404   \n",
       "01/01/2018 01:25:00      1    1             85     21.518              -0.286   \n",
       "01/01/2018 01:30:00      1    1             90     -8.024              21.518   \n",
       "01/01/2018 01:35:00      1    1             95    -36.888              -8.024   \n",
       "01/01/2018 01:40:00      1    1            100   -102.888             -36.888   \n",
       "\n",
       "                     Previous_RT  Previous_RT_2  Previous_Load_Diff_2  \n",
       "Interval                                                               \n",
       "01/01/2018 01:20:00    24.118414      27.302014             18.136000  \n",
       "01/01/2018 01:25:00    24.729624      26.031712              8.197667  \n",
       "01/01/2018 01:30:00    28.389152      25.745730              8.545333  \n",
       "01/01/2018 01:35:00    28.267911      27.128896              4.402667  \n",
       "01/01/2018 01:40:00    32.869229      29.842097             -7.798000  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding previous-interval and moving averages\n",
    "DART2018_1 = DART2018.iloc[1:,:]\n",
    "previous_load_diff = DART2018['Load_Diff'].iloc[0:-1].values\n",
    "DART2018_1['Previous_Load_Diff'] = previous_load_diff\n",
    "previous_RT = DART2018['LMP_RT'].iloc[0:-1].values\n",
    "DART2018_1['Previous_RT'] = previous_RT\n",
    "\n",
    "step = 3\n",
    "previous_RT = DART2018_1['LMP_RT'].iloc[0:(DART2018_1.shape[0] - step)].values\n",
    "previous_means_RT = np.empty(previous_RT.size)\n",
    "previous_load = DART2018_1['Load_Diff'].iloc[0:(DART2018_1.shape[0] - step)].values\n",
    "previous_means_load = np.empty(previous_load.size)\n",
    "for i in range(DART2018_1.shape[0] - step):\n",
    "    previous_means_RT[i] = previous_RT[i:i+step].mean()\n",
    "    previous_means_load[i] = previous_load[i:i+step].mean()\n",
    "DART2018_2 = DART2018_1.iloc[step:,:]\n",
    "DART2018_2['Previous_RT_2'] = previous_means_RT\n",
    "DART2018_2['Previous_Load_Diff_2'] = previous_means_load\n",
    "\n",
    "DART2018_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90%\n",
      "MAPE ± std\n",
      "11 predictors: 10.279775063650249 ± 3.44978717211043\n",
      "10 predictors: 10.243467942129993 ± 3.770628967991666\n",
      "# of errors: 0\n"
     ]
    }
   ],
   "source": [
    "# 11 features vs more\n",
    "\n",
    "np.seterr(divide='print',invalid='print')\n",
    "\n",
    "n = 10\n",
    "PE_11_list = []\n",
    "PE_12_list = []\n",
    "errors = 0\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(1,13):\n",
    "        by_month = DART2018_2[DART2018_2['Month']==j]\n",
    "\n",
    "        train, test = train_test_split(by_month, test_size=0.33)\n",
    "\n",
    "        train_data = train.groupby('Local Time')[['LMP_RT','LMP_DA','Load','Wind','Weekday','Load_Diff', 'Previous_Load_Diff',\n",
    "                                                  'Previous_RT', 'Previous_Load_Diff_2', 'Previous_RT_2']].mean()\n",
    "        train_data['RT_std'] = train.groupby('Local Time')['LMP_RT'].std()\n",
    "        train_data['DA_std'] = train.groupby('Local Time')['LMP_DA'].std()        \n",
    "        test_data = test.groupby('Local Time')[['LMP_RT','LMP_DA','Load','Wind','Weekday','Load_Diff', 'Previous_Load_Diff', \n",
    "                                                'Previous_RT', 'Previous_Load_Diff_2', 'Previous_RT_2']].mean()\n",
    "        test_data['RT_std'] = test.groupby('Local Time')['LMP_RT'].std()\n",
    "        test_data['DA_std'] = test.groupby('Local Time')['LMP_DA'].std() \n",
    "        test_data_copy = test_data.copy()\n",
    "        \n",
    "        test_data_copy['fitted RT (11)'] = np.zeros(test_data_copy.index.shape[0])\n",
    "        test_data_copy['fitted RT (10)'] = np.zeros(test_data_copy.index.shape[0])\n",
    "        branch_dfs = sklearn_clusters_2(train_data, 2, False)\n",
    "        for cluster in branch_dfs:\n",
    "            try:\n",
    "                result11 = smf.ols(formula=\"\"\"LMP_RT ~ LMP_DA + RT_std + DA_std + Load + Wind + Weekday + Load_Diff + \n",
    "                                    Previous_Load_Diff + Previous_Load_Diff_2 + Previous_RT + Previous_RT_2\"\"\", data=cluster).fit()\n",
    "                result12 = smf.ols(formula=\"\"\"LMP_RT ~ LMP_DA + RT_std + DA_std + Load + Wind + Load_Diff + \n",
    "                                    Previous_Load_Diff + Previous_Load_Diff_2 +\n",
    "                                    Previous_RT + Previous_RT_2\"\"\", data=cluster).fit()\n",
    "                for hour in cluster.index:\n",
    "                    test_data_copy['fitted RT (11)'].loc[hour] = (\n",
    "                                                test_data_copy['Previous_RT_2'].loc[hour]*result11.params[11] +  \n",
    "                                                test_data_copy['Previous_RT'].loc[hour]*result11.params[10] +  \n",
    "                                                test_data_copy['Previous_Load_Diff_2'].loc[hour]*result11.params[9] + \n",
    "                                                test_data_copy['Previous_Load_Diff'].loc[hour]*result11.params[8] + \n",
    "                                                test_data_copy['Load_Diff'].loc[hour]*result11.params[7] + \n",
    "                                                test_data_copy['Weekday'].loc[hour]*result11.params[6] + \n",
    "                                                test_data_copy['Wind'].loc[hour]*result11.params[5] + \n",
    "                                                test_data_copy['Load'].loc[hour]*result11.params[4] + \n",
    "                                                test_data_copy['DA_std'].loc[hour]*result11.params[3] + \n",
    "                                                test_data_copy['RT_std'].loc[hour]*result11.params[2] + \n",
    "                                                test_data_copy['LMP_DA'].loc[hour]*result11.params[1] + \n",
    "                                                result11.params[0])\n",
    "                    test_data_copy['fitted RT (10)'].loc[hour] = (\n",
    "                                                test_data_copy['Previous_RT_2'].loc[hour]*result12.params[10] +  \n",
    "                                                test_data_copy['Previous_RT'].loc[hour]*result12.params[9] +\n",
    "                                                test_data_copy['Previous_Load_Diff_2'].loc[hour]*result12.params[8] + \n",
    "                                                test_data_copy['Previous_Load_Diff'].loc[hour]*result12.params[7] + \n",
    "                                                test_data_copy['Load_Diff'].loc[hour]*result12.params[6] + \n",
    "                                                test_data_copy['Wind'].loc[hour]*result12.params[5] + \n",
    "                                                test_data_copy['Load'].loc[hour]*result12.params[4] + \n",
    "                                                test_data_copy['DA_std'].loc[hour]*result12.params[3] + \n",
    "                                                test_data_copy['RT_std'].loc[hour]*result12.params[2] + \n",
    "                                                test_data_copy['LMP_DA'].loc[hour]*result12.params[1] + \n",
    "                                                result12.params[0])\n",
    "            except:\n",
    "                errors += 1\n",
    "                print('\\nerror occurred at i={} month={}'.format(i,j))\n",
    "                continue\n",
    "        PE_11_list.append(pe(test_data_copy['fitted RT (11)'], test_data_copy['LMP_RT']).mean())\n",
    "        PE_12_list.append(pe(test_data_copy['fitted RT (10)'], test_data_copy['LMP_RT']).mean())\n",
    "        \n",
    "    print(f'\\r{10*i}%',end='')\n",
    "\n",
    "PE_11_array = np.array(PE_11_list)\n",
    "PE_12_array = np.array(PE_12_list)\n",
    "\n",
    "print('\\nMAPE \\u00B1 std')\n",
    "print('11 predictors: {} \\u00B1 {}'.format(PE_11_array.mean(), PE_11_array.std()))\n",
    "print('10 predictors: {} \\u00B1 {}'.format(PE_12_array.mean(), PE_12_array.std()))\n",
    "print('# of errors: {}'.format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.884142166186782, 10.027315463308623)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE_12_array[PE_12_array!=PE_12_array.max()].mean(), PE_11_array[PE_11_array!=PE_11_array.max()].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
