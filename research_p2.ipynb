{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from scipy import stats\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPP_path = r'C:\\Users\\felip\\Desktop\\Electricity\\Energy Market\\Energy Market (SPP)'\n",
    "\n",
    "def add_info(df):\n",
    "    intervals = df[df.columns[0]].values.tolist()\n",
    "    dates = []\n",
    "    times = []\n",
    "    weekday = []\n",
    "    months = []\n",
    "    days = []\n",
    "    hour = []\n",
    "    for interval in intervals:\n",
    "        date = interval.split(' ')[0]\n",
    "        try:\n",
    "            date = dt.datetime.strptime(date,'%Y-%m-%d').date()\n",
    "        except:\n",
    "            date = dt.datetime.strptime(date,'%m/%d/%Y').date()            \n",
    "        dates.append(date)\n",
    "        months.append(date.month)\n",
    "        days.append(date.day)\n",
    "        if date.weekday() < 5:\n",
    "            weekday.append(True)\n",
    "        else:\n",
    "            weekday.append(False)\n",
    "        time = interval.split(' ')[1].split('.')[0]\n",
    "        time = dt.datetime.strptime(time,'%H:%M:%S').time()\n",
    "        times.append(time)\n",
    "        hour.append(dt.time(time.hour))\n",
    "    df['Local Date'] = np.array(dates)\n",
    "    df['Local Time'] = np.array(times)\n",
    "    df['Hour'] = np.array(hour)\n",
    "    df['Weekday'] = np.array(weekday)\n",
    "    df['Month'] = np.array(months)\n",
    "    df['Day'] = np.array(days)\n",
    "    return df\n",
    "\n",
    "def GMT2CT(s):\n",
    "    date = s.split('T')[0]\n",
    "    date = dt.datetime.strptime(date,'%Y-%m-%d').date()\n",
    "    time = s.split('T')[1][:-1]\n",
    "    hour = int(time.split(':')[0])\n",
    "    if hour >= 6:\n",
    "        hour = hour - 6\n",
    "    else:\n",
    "        hour = 24 + (hour - 6)\n",
    "        date = date - timedelta(1)\n",
    "    time = str(hour) + ':' + time.split(':')[1] + ':' + time.split(':')[2]\n",
    "    time = dt.datetime.strptime(time,'%H:%M:%S').time()\n",
    "    return [date, time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_mix_2018 = pd.read_csv(SPP_path + '\\Generation Mix By Fuel Type\\GenMix_2018.csv')\n",
    "list_intervals = gen_mix_2018[gen_mix_2018.columns[0]].values.tolist()\n",
    "local_time = []\n",
    "local_date = []\n",
    "for value in list_intervals:\n",
    "    local_date.append(GMT2CT(value)[0])\n",
    "    local_time.append(GMT2CT(value)[1])\n",
    "gen_mix_2018['Local Date'] = np.array(local_date)\n",
    "gen_mix_2018['Local Time'] = np.array(local_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_31 = []\n",
    "for n in range(1,10):\n",
    "    days_31.append('0'+str(n))\n",
    "for n in range(10,32):\n",
    "    days_31.append(str(n))\n",
    "cal_dict = {'01':days_31,\n",
    "            '02':days_31[0:28],\n",
    "            '03':days_31,\n",
    "           '04':days_31[0:-1],\n",
    "            '05':days_31,\n",
    "            '06':days_31[0:-1],\n",
    "           '07':days_31,\n",
    "            '08':days_31,\n",
    "            '09':days_31[0:-1],\n",
    "           '10':days_31,\n",
    "           '11':days_31[0:-1],\n",
    "           '12':days_31}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>GMT Interval</th>\n",
       "      <th>Settlement Location Name</th>\n",
       "      <th>PNODE Name</th>\n",
       "      <th>LMP</th>\n",
       "      <th>MLC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>MEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2018 00:05:00</td>\n",
       "      <td>01/01/2018 06:05:00</td>\n",
       "      <td>AEC</td>\n",
       "      <td>SOUC</td>\n",
       "      <td>255.8769</td>\n",
       "      <td>5.4654</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>250.4115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2018 00:05:00</td>\n",
       "      <td>01/01/2018 06:05:00</td>\n",
       "      <td>AECC_CSWS</td>\n",
       "      <td>CSWS_AECC_LA</td>\n",
       "      <td>262.5802</td>\n",
       "      <td>5.0312</td>\n",
       "      <td>7.1375</td>\n",
       "      <td>250.4115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2018 00:05:00</td>\n",
       "      <td>01/01/2018 06:05:00</td>\n",
       "      <td>AECC_ELKINS</td>\n",
       "      <td>CSWSELKINSUNELKINS_RA</td>\n",
       "      <td>270.2234</td>\n",
       "      <td>3.0020</td>\n",
       "      <td>16.8099</td>\n",
       "      <td>250.4115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2018 00:05:00</td>\n",
       "      <td>01/01/2018 06:05:00</td>\n",
       "      <td>AECC_FITZHUGH</td>\n",
       "      <td>CSWSFITZHUGHPLT1</td>\n",
       "      <td>257.2724</td>\n",
       "      <td>6.8609</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>250.4115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2018 00:05:00</td>\n",
       "      <td>01/01/2018 06:05:00</td>\n",
       "      <td>AECC_FLTCREEK</td>\n",
       "      <td>CSWSFLINTCRKUN1_JOU_AECC_RA</td>\n",
       "      <td>266.5657</td>\n",
       "      <td>-3.0577</td>\n",
       "      <td>19.2119</td>\n",
       "      <td>250.4115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Interval         GMT Interval  Settlement Location Name  \\\n",
       "0  01/01/2018 00:05:00  01/01/2018 06:05:00                       AEC   \n",
       "1  01/01/2018 00:05:00  01/01/2018 06:05:00                 AECC_CSWS   \n",
       "2  01/01/2018 00:05:00  01/01/2018 06:05:00               AECC_ELKINS   \n",
       "3  01/01/2018 00:05:00  01/01/2018 06:05:00             AECC_FITZHUGH   \n",
       "4  01/01/2018 00:05:00  01/01/2018 06:05:00             AECC_FLTCREEK   \n",
       "\n",
       "                    PNODE Name       LMP     MLC      MCC       MEC  \n",
       "0                         SOUC  255.8769  5.4654   0.0000  250.4115  \n",
       "1                 CSWS_AECC_LA  262.5802  5.0312   7.1375  250.4115  \n",
       "2        CSWSELKINSUNELKINS_RA  270.2234  3.0020  16.8099  250.4115  \n",
       "3             CSWSFITZHUGHPLT1  257.2724  6.8609   0.0000  250.4115  \n",
       "4  CSWSFLINTCRKUN1_JOU_AECC_RA  266.5657 -3.0577  19.2119  250.4115  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening and concatenating RT datasets\n",
    "path = r'C:\\Users\\felip\\Desktop\\Electricity\\Energy Market\\Energy Market (SPP)\\RT\\2018'\n",
    "RT_path = 'RTBM-LMP-DAILY-SL-2018'\n",
    "end = '.csv'\n",
    "dfs = []\n",
    "for key in cal_dict.keys():\n",
    "    for value in cal_dict[key]:\n",
    "        dfs.append(pd.read_csv(path+'\\\\'+key+'\\\\By_Day\\\\'+RT_path+key+value+end))\n",
    "RT = pd.concat(dfs)\n",
    "RT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>LMP</th>\n",
       "      <th>Local Date</th>\n",
       "      <th>Local Time</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interval</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/01/2018 00:05:00</th>\n",
       "      <td>01/01/2018 00:05:00</td>\n",
       "      <td>246.567610</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>00:05:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 00:10:00</th>\n",
       "      <td>01/01/2018 00:10:00</td>\n",
       "      <td>64.864068</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>00:10:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 00:15:00</th>\n",
       "      <td>01/01/2018 00:15:00</td>\n",
       "      <td>164.686048</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 00:20:00</th>\n",
       "      <td>01/01/2018 00:20:00</td>\n",
       "      <td>173.867912</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/01/2018 00:25:00</th>\n",
       "      <td>01/01/2018 00:25:00</td>\n",
       "      <td>163.353003</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>00:25:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Interval         LMP  Local Date Local Time  \\\n",
       "Interval                                                                      \n",
       "01/01/2018 00:05:00  01/01/2018 00:05:00  246.567610  2018-01-01   00:05:00   \n",
       "01/01/2018 00:10:00  01/01/2018 00:10:00   64.864068  2018-01-01   00:10:00   \n",
       "01/01/2018 00:15:00  01/01/2018 00:15:00  164.686048  2018-01-01   00:15:00   \n",
       "01/01/2018 00:20:00  01/01/2018 00:20:00  173.867912  2018-01-01   00:20:00   \n",
       "01/01/2018 00:25:00  01/01/2018 00:25:00  163.353003  2018-01-01   00:25:00   \n",
       "\n",
       "                         Hour  Weekday  Month  Day  \n",
       "Interval                                            \n",
       "01/01/2018 00:05:00  00:00:00     True      1    1  \n",
       "01/01/2018 00:10:00  00:00:00     True      1    1  \n",
       "01/01/2018 00:15:00  00:00:00     True      1    1  \n",
       "01/01/2018 00:20:00  00:00:00     True      1    1  \n",
       "01/01/2018 00:25:00  00:00:00     True      1    1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RT2018_aggloc = RT.groupby('Interval')[['Interval',' LMP']].agg({'Interval':'first',\n",
    "                                                                    ' LMP':'mean'})\n",
    "RT2018 = add_info(RT2018_aggloc)\n",
    "RT2018 = RT2018.rename(columns={' LMP':'LMP'})\n",
    "RT2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>GMTIntervalEnd</th>\n",
       "      <th>Settlement Location</th>\n",
       "      <th>Pnode</th>\n",
       "      <th>LMP</th>\n",
       "      <th>MLC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>MEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2018 01:00:00</td>\n",
       "      <td>01/01/2018 07:00:00</td>\n",
       "      <td>AEC</td>\n",
       "      <td>SOUC</td>\n",
       "      <td>39.6809</td>\n",
       "      <td>0.8665</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>38.2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2018 01:00:00</td>\n",
       "      <td>01/01/2018 07:00:00</td>\n",
       "      <td>AECC_CSWS</td>\n",
       "      <td>CSWS_AECC_LA</td>\n",
       "      <td>38.3723</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>-0.5781</td>\n",
       "      <td>38.2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2018 01:00:00</td>\n",
       "      <td>01/01/2018 07:00:00</td>\n",
       "      <td>AECC_ELKINS</td>\n",
       "      <td>CSWSELKINSUNELKINS_RA</td>\n",
       "      <td>38.4189</td>\n",
       "      <td>0.4093</td>\n",
       "      <td>-0.2077</td>\n",
       "      <td>38.2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2018 01:00:00</td>\n",
       "      <td>01/01/2018 07:00:00</td>\n",
       "      <td>AECC_FITZHUGH</td>\n",
       "      <td>CSWSFITZHUGHPLT1</td>\n",
       "      <td>38.5076</td>\n",
       "      <td>1.0540</td>\n",
       "      <td>-0.7637</td>\n",
       "      <td>38.2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2018 01:00:00</td>\n",
       "      <td>01/01/2018 07:00:00</td>\n",
       "      <td>AECC_FLTCREEK</td>\n",
       "      <td>CSWSFLINTCRKUN1_JOU_AECC_RA</td>\n",
       "      <td>37.8395</td>\n",
       "      <td>-0.4387</td>\n",
       "      <td>0.0609</td>\n",
       "      <td>38.2173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Interval       GMTIntervalEnd Settlement Location  \\\n",
       "0  01/01/2018 01:00:00  01/01/2018 07:00:00                 AEC   \n",
       "1  01/01/2018 01:00:00  01/01/2018 07:00:00           AECC_CSWS   \n",
       "2  01/01/2018 01:00:00  01/01/2018 07:00:00         AECC_ELKINS   \n",
       "3  01/01/2018 01:00:00  01/01/2018 07:00:00       AECC_FITZHUGH   \n",
       "4  01/01/2018 01:00:00  01/01/2018 07:00:00       AECC_FLTCREEK   \n",
       "\n",
       "                         Pnode      LMP     MLC     MCC      MEC  \n",
       "0                         SOUC  39.6809  0.8665  0.5970  38.2174  \n",
       "1                 CSWS_AECC_LA  38.3723  0.7331 -0.5781  38.2173  \n",
       "2        CSWSELKINSUNELKINS_RA  38.4189  0.4093 -0.2077  38.2173  \n",
       "3             CSWSFITZHUGHPLT1  38.5076  1.0540 -0.7637  38.2173  \n",
       "4  CSWSFLINTCRKUN1_JOU_AECC_RA  37.8395 -0.4387  0.0609  38.2173  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening and concatenating DA datasets\n",
    "path = r'C:\\Users\\felip\\Desktop\\Electricity\\Energy Market\\Energy Market (SPP)\\DA\\2018'\n",
    "DA_path = 'DA-LMP-SL-2018'\n",
    "end = '0100.csv'\n",
    "dfs = []\n",
    "for key in cal_dict.keys():\n",
    "    for value in cal_dict[key]:\n",
    "        dfs.append(pd.read_csv(path+'\\\\'+key+'\\\\By_Day\\\\'+DA_path+key+value+end))\n",
    "DA2018 = pd.concat(dfs)\n",
    "DA2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>GMTIntervalEnd</th>\n",
       "      <th>Settlement Location</th>\n",
       "      <th>Pnode</th>\n",
       "      <th>LMP</th>\n",
       "      <th>MLC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>MEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2018 01:00:00</td>\n",
       "      <td>01/01/2018 07:00:00</td>\n",
       "      <td>AEC</td>\n",
       "      <td>SOUC</td>\n",
       "      <td>39.6809</td>\n",
       "      <td>0.8665</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>38.2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2018 01:00:00</td>\n",
       "      <td>01/01/2018 07:00:00</td>\n",
       "      <td>AECC_CSWS</td>\n",
       "      <td>CSWS_AECC_LA</td>\n",
       "      <td>38.3723</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>-0.5781</td>\n",
       "      <td>38.2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2018 01:00:00</td>\n",
       "      <td>01/01/2018 07:00:00</td>\n",
       "      <td>AECC_ELKINS</td>\n",
       "      <td>CSWSELKINSUNELKINS_RA</td>\n",
       "      <td>38.4189</td>\n",
       "      <td>0.4093</td>\n",
       "      <td>-0.2077</td>\n",
       "      <td>38.2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2018 01:00:00</td>\n",
       "      <td>01/01/2018 07:00:00</td>\n",
       "      <td>AECC_FITZHUGH</td>\n",
       "      <td>CSWSFITZHUGHPLT1</td>\n",
       "      <td>38.5076</td>\n",
       "      <td>1.0540</td>\n",
       "      <td>-0.7637</td>\n",
       "      <td>38.2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2018 01:00:00</td>\n",
       "      <td>01/01/2018 07:00:00</td>\n",
       "      <td>AECC_FLTCREEK</td>\n",
       "      <td>CSWSFLINTCRKUN1_JOU_AECC_RA</td>\n",
       "      <td>37.8395</td>\n",
       "      <td>-0.4387</td>\n",
       "      <td>0.0609</td>\n",
       "      <td>38.2173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Interval       GMTIntervalEnd Settlement Location  \\\n",
       "0  01/01/2018 01:00:00  01/01/2018 07:00:00                 AEC   \n",
       "1  01/01/2018 01:00:00  01/01/2018 07:00:00           AECC_CSWS   \n",
       "2  01/01/2018 01:00:00  01/01/2018 07:00:00         AECC_ELKINS   \n",
       "3  01/01/2018 01:00:00  01/01/2018 07:00:00       AECC_FITZHUGH   \n",
       "4  01/01/2018 01:00:00  01/01/2018 07:00:00       AECC_FLTCREEK   \n",
       "\n",
       "                         Pnode      LMP     MLC     MCC      MEC  \n",
       "0                         SOUC  39.6809  0.8665  0.5970  38.2174  \n",
       "1                 CSWS_AECC_LA  38.3723  0.7331 -0.5781  38.2173  \n",
       "2        CSWSELKINSUNELKINS_RA  38.4189  0.4093 -0.2077  38.2173  \n",
       "3             CSWSFITZHUGHPLT1  38.5076  1.0540 -0.7637  38.2173  \n",
       "4  CSWSFLINTCRKUN1_JOU_AECC_RA  37.8395 -0.4387  0.0609  38.2173  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA2018_aggloc = DA2018.groupby('Interval')[['Interval','LMP']].agg({'Interval':'first',\n",
    "                                                                    'LMP':'mean'})\n",
    "DA2018_aggloc = add_info(DA2018_aggloc)\n",
    "DA2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssr(prediction, test):\n",
    "    return ((prediction - test)**2).sum()\n",
    "def pe(prediction, test):\n",
    "    return (abs((prediction - test)/test))*100\n",
    "def filler(df, DA):\n",
    "    price_list = df[DA].values.tolist()\n",
    "    value = 0.0\n",
    "    new_list = []\n",
    "    for price in price_list:\n",
    "        if math.isnan(price)==True:\n",
    "            new_list.append(value)\n",
    "        else:\n",
    "            value = price\n",
    "            new_list.append(price)\n",
    "    df[DA] = np.array(new_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = DA2018_aggloc.iloc[:,0:2].join(RT2018,how='right',lsuffix='_DA',rsuffix='_RT')\n",
    "DART2018_5min = filler(comparison, 'LMP_DA')\n",
    "gen_2018 = gen_mix_2018\n",
    "new_index = []\n",
    "for i in range(gen_2018.shape[0]):\n",
    "    new_index.append(gen_2018['Local Date'].iloc[i].strftime(\"%m/%d/%Y\") + ' ' + gen_2018['Local Time'].iloc[i].strftime(\"%H:%M:%S\"))\n",
    "gen_2018.index = np.array(new_index)\n",
    "DART_gen_2018 = gen_2018.join(DART2018_5min,how='right',lsuffix='_gen',rsuffix='_price')\n",
    "DART_gen_2018 = DART_gen_2018.rename(columns={' Average Actual Load':'Load',\n",
    "                                             ' Wind Self':'Wind',\n",
    "                                             ' Coal Market':'Coal_Mkt',\n",
    "                                             ' Coal Self':'Coal_Self',\n",
    "                                             'Local Time_price':'Local Time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssr_split4(df, s):\n",
    "    if df.shape[0]>(288/4):\n",
    "        smallest_y = 0\n",
    "        smallest_x = 0\n",
    "        for i in range(0, df.shape[0]):\n",
    "            try:\n",
    "                y_avg1 = df[s][0:i+1].values.mean()\n",
    "                y_avg2 = df[s][i:df.shape[0]].values.mean()\n",
    "                ssr = ((df[s][0:i+1].values - y_avg1)**2).sum() + ((df[s][i:df.shape[0]].values - y_avg2)**2).sum()\n",
    "                if i == 0:\n",
    "                    smallest_y = ssr\n",
    "                if ssr < smallest_y:\n",
    "                    smallest_y = ssr\n",
    "                    smallest_x = i\n",
    "            except:\n",
    "                y_avg1 = df[s].values.mean()\n",
    "                ssr = ((df[s][0:i+1].values - y_avg1)**2).sum()\n",
    "                if ssr < smallest_y:\n",
    "                    smallest_y = ssr\n",
    "                    smallest_x = i\n",
    "        smallest = df.iloc[0:smallest_x+1]\n",
    "        largest = df.iloc[smallest_x+1:]\n",
    "        if smallest.shape[0] > largest.shape[0]:\n",
    "            temp = smallest\n",
    "            smallest = largest\n",
    "            largest = temp\n",
    "        concat = [smallest] + [ssr_split4(largest, s)]\n",
    "        return concat\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def unnest(l, empty_l):\n",
    "    for i in l:\n",
    "        if type(i) == list:\n",
    "            unnest(i, empty_l)\n",
    "        else:\n",
    "            empty_l.append(i)\n",
    "            \n",
    "def unnested_df(l):\n",
    "    for df in l:\n",
    "        means = np.empty(df.shape[0])\n",
    "        means.fill(df['LMP_RT'].mean())\n",
    "        df['Means'] = means\n",
    "    unnested = pd.concat(l)\n",
    "    unnested['Time'] = unnested.index\n",
    "    unnested = unnested.sort_values('Time')\n",
    "    return unnested\n",
    "\n",
    "def sklearn_clusters(train_df, test_df):\n",
    "    # converting datetime to float\n",
    "    minutes = []\n",
    "    for time in train_df.index:\n",
    "        minutes.append(time.hour * 60 + time.minute + 0.1)\n",
    "    train_df['minutes'] = np.array(minutes)\n",
    "    minutes = []\n",
    "    for time in test_df.index:\n",
    "        minutes.append(time.hour * 60 + time.minute + 0.1)\n",
    "    test_df['minutes'] = np.array(minutes)\n",
    "    # testing existing module\n",
    "    X = train_df['minutes'].values.reshape(-1,1)\n",
    "    y = train_df['LMP_RT']\n",
    "    # Fit regression model\n",
    "    regr_1 = DecisionTreeRegressor(max_depth=3)\n",
    "    regr_1.fit(X, y)\n",
    "    # Predict\n",
    "    X_test = test_df['minutes'].values.reshape(-1,1)\n",
    "    y_1 = regr_1.predict(X_test)\n",
    "    test_df['sklearn cluster'] = y_1\n",
    "    price_leaves = []\n",
    "    for price in y_1:\n",
    "        if price not in price_leaves:\n",
    "            price_leaves.append(price)\n",
    "    branch_dfs = []\n",
    "    for price in price_leaves:\n",
    "        branch_dfs.append(test_df[test_df['sklearn cluster']==price])\n",
    "    return branch_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "0%\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "10%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "20%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "30%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "40%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "50%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "60%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "70%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "80%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "90%\n",
      "custom cluster:\n",
      "\tMAPE: 13.929944206831607;\n",
      "\tMean R^2: 0.8820724001705917;\n",
      "sklearn clusters:\n",
      "\tMAPE: 7.1029412541398855;\n",
      "\tMean R^2: nan;\n",
      "errors filling predictions: 0\n",
      "mean of all valid R^2: -inf\n",
      "2.5210084033613467% of R^2 were invalid (nan or inf)\n"
     ]
    }
   ],
   "source": [
    "# system-wide, 5 predictors\n",
    "# multi or single clustered -- comparings R^2\n",
    "\n",
    "np.seterr(divide='print')\n",
    "def err_handler(type, flag):\n",
    "    print(\"Floating point error (%s) with flag %s\" % (type, flag))\n",
    "saved_handler = np.seterrcall(err_handler)\n",
    "save_err = np.seterr(all='call')\n",
    "\n",
    "n = 10\n",
    "custom_PE_array = np.empty(n)\n",
    "custom_R2_array = np.empty(n)\n",
    "sklearn_PE_array = np.empty(n)\n",
    "sklearn_R2_array = np.empty(n)\n",
    "\n",
    "check = 0\n",
    "R2 = []\n",
    "\n",
    "for i in range(n):\n",
    "    custom_PE_list = []\n",
    "    custom_R2_list = []\n",
    "    sklearn_PE_list = []\n",
    "    sklearn_R2_list = []\n",
    "\n",
    "    for j in range(1,13):\n",
    "        by_month = DART_gen_2018[DART_gen_2018['Month']==j]\n",
    "\n",
    "        train, test = train_test_split(by_month, test_size=0.33)\n",
    "\n",
    "        train_data = train.groupby('Local Time')[['LMP_RT','LMP_DA','Load','Wind']].mean()\n",
    "        train_data['RT_sem'] = train.groupby('Local Time')['LMP_RT'].sem()\n",
    "        train_data['DA_sem'] = train.groupby('Local Time')['LMP_DA'].sem()        \n",
    "\n",
    "        test_data = test.groupby('Local Time')[['LMP_RT','LMP_DA','Load','Wind']].mean()\n",
    "        test_data['RT_sem'] = test.groupby('Local Time')['LMP_RT'].sem()\n",
    "        test_data['DA_sem'] = test.groupby('Local Time')['LMP_DA'].sem() \n",
    "\n",
    "        test_data_copy = test_data.copy()\n",
    "        \n",
    "        size = test_data_copy.index.shape[0]\n",
    "        test_data_copy['fitted RT (custom)'] = np.zeros(size)            \n",
    "        cl = []\n",
    "        unnest(ssr_split4(train_data, 'LMP_RT'), cl)\n",
    "        for cluster in cl:\n",
    "            result = smf.ols(formula=\"LMP_RT ~ LMP_DA + RT_sem + DA_sem + Load + Wind\", data=cluster).fit()\n",
    "            custom_R2_list.append(result.rsquared)\n",
    "            for hour in cluster.index:\n",
    "                try:\n",
    "                    test_data_copy['fitted RT (custom)'].loc[hour] = ( \n",
    "                                                test_data_copy['Wind'].loc[hour]*result.params[5] + \n",
    "                                                test_data_copy['Load'].loc[hour]*result.params[4] + \n",
    "                                                test_data_copy['DA_sem'].loc[hour]*result.params[3] + \n",
    "                                                test_data_copy['RT_sem'].loc[hour]*result.params[2] + \n",
    "                                                test_data_copy['LMP_DA'].loc[hour]*result.params[1] + \n",
    "                                                result.params[0])\n",
    "                except:\n",
    "                    continue\n",
    "        custom_PE_list.append(pe(test_data_copy['fitted RT (custom)'], test_data_copy['LMP_RT']).mean())\n",
    "        \n",
    "                \n",
    "        branch_dfs = sklearn_clusters(train_data, test_data)\n",
    "        size = test_data_copy.index.shape[0]\n",
    "        test_data_copy['fitted RT (sklearn)'] = np.zeros(size) \n",
    "        for cluster in branch_dfs:\n",
    "            result = smf.ols(formula=\"LMP_RT ~ LMP_DA + RT_sem + DA_sem + Load + Wind\", data=cluster).fit()\n",
    "            sklearn_R2_list.append(result.rsquared)\n",
    "            R2.append(result.rsquared)\n",
    "            for hour in cluster.index:\n",
    "                test_data_copy['fitted RT (sklearn)'].loc[hour] = ( \n",
    "                                            test_data_copy['Wind'].loc[hour]*result.params[5] + \n",
    "                                            test_data_copy['Load'].loc[hour]*result.params[4] + \n",
    "                                            test_data_copy['DA_sem'].loc[hour]*result.params[3] + \n",
    "                                            test_data_copy['RT_sem'].loc[hour]*result.params[2] + \n",
    "                                            test_data_copy['LMP_DA'].loc[hour]*result.params[1] + \n",
    "                                            result.params[0])\n",
    "        sklearn_PE_list.append(pe(test_data_copy['fitted RT (sklearn)'], test_data_copy['LMP_RT']).mean())\n",
    "            \n",
    "            \n",
    "        check += np.where(test_data_copy['fitted RT (custom)']==0.0,1,0).sum()\n",
    "        check += np.where(test_data_copy['fitted RT (sklearn)']==0.0,1,0).sum()\n",
    "        if check > 0:\n",
    "            print(check)\n",
    "            break\n",
    "                \n",
    "    print('{}%'.format(10*i))\n",
    "\n",
    "    custom_PE_array[i] = np.array(custom_PE_list).mean()\n",
    "    custom_R2_array[i] = np.array(custom_R2_list).mean()\n",
    "    sklearn_PE_array[i] = np.array(sklearn_PE_list).mean()\n",
    "    sklearn_R2_array[i] = np.array(sklearn_R2_list).mean()\n",
    "\n",
    "\n",
    "print('custom cluster:\\n\\tMAPE: {};\\n\\tMean R^2: {};'.format(custom_PE_array.mean(),custom_R2_array.mean()))\n",
    "print('sklearn clusters:\\n\\tMAPE: {};\\n\\tMean R^2: {};'.format(sklearn_PE_array.mean(),sklearn_R2_array.mean()))\n",
    "print('errors filling predictions: {}'.format(check))\n",
    "len1 = len(R2)\n",
    "for value in R2:\n",
    "    if (value == np.inf) or (value == -np.inf):\n",
    "        R2.remove(value)\n",
    "len2 = len(R2)\n",
    "print('mean of all valid R^2: {}'.format(np.nanmean(R2)))\n",
    "print('{}% of R^2 were invalid (nan or inf)'.format(100*(1 - len2/len1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raising so many warnings, but was not able to track them down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def means_dict(d):\n",
    "    means_d = {}\n",
    "    for key in d.keys():\n",
    "        means_d[key] = np.nanmean(np.array(d[key]))\n",
    "    return means_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "0%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "10%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "20%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "30%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "40%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "50%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "60%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "70%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (invalid value) with flag 8\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "80%\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "Floating point error (divide by zero) with flag 1\n",
      "90%\n",
      "MAPE: 7.200987479043176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Intercept': 0.38024158525727747,\n",
       " 'LMP_DA': 0.37122281332225293,\n",
       " 'RT_sem': 0.08602462617380587,\n",
       " 'DA_sem': 0.370103006944041,\n",
       " 'Load': 0.24915185070934887,\n",
       " 'Wind': 0.19965662021604613}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.seterr(divide='print')\n",
    "def err_handler(type, flag):\n",
    "    print(\"Floating point error (%s) with flag %s\" % (type, flag))\n",
    "saved_handler = np.seterrcall(err_handler)\n",
    "save_err = np.seterr(all='call')\n",
    "n = 10\n",
    "sklearn_PE_array = np.empty(n)\n",
    "pvalues = {'Intercept':[],\n",
    "          'LMP_DA':[],\n",
    "          'RT_sem':[],\n",
    "          'DA_sem':[],\n",
    "          'Load':[],\n",
    "          'Wind':[]}\n",
    "for i in range(n):\n",
    "    sklearn_PE_list = []\n",
    "    for j in range(1,13):\n",
    "        by_month = DART_gen_2018[DART_gen_2018['Month']==j]\n",
    "\n",
    "        train, test = train_test_split(by_month, test_size=0.33)\n",
    "\n",
    "        train_data = train.groupby('Local Time')[['LMP_RT','LMP_DA','Load','Wind']].mean()\n",
    "        train_data['RT_sem'] = train.groupby('Local Time')['LMP_RT'].sem()\n",
    "        train_data['DA_sem'] = train.groupby('Local Time')['LMP_DA'].sem()        \n",
    "\n",
    "        test_data = test.groupby('Local Time')[['LMP_RT','LMP_DA','Load','Wind']].mean()\n",
    "        test_data['RT_sem'] = test.groupby('Local Time')['LMP_RT'].sem()\n",
    "        test_data['DA_sem'] = test.groupby('Local Time')['LMP_DA'].sem() \n",
    "        test_data_copy = test_data.copy()\n",
    "        test_data_copy['fitted RT (sklearn)'] = np.zeros(test_data_copy.index.shape[0])\n",
    "        branch_dfs = sklearn_clusters(train_data, test_data)\n",
    "        for cluster in branch_dfs:\n",
    "            result = smf.ols(formula=\"LMP_RT ~ LMP_DA + RT_sem + DA_sem + Load + Wind\", data=cluster).fit()\n",
    "            for hour in cluster.index:\n",
    "                test_data_copy['fitted RT (sklearn)'].loc[hour] = ( \n",
    "                                            test_data_copy['Wind'].loc[hour]*result.params[5] + \n",
    "                                            test_data_copy['Load'].loc[hour]*result.params[4] + \n",
    "                                            test_data_copy['DA_sem'].loc[hour]*result.params[3] + \n",
    "                                            test_data_copy['RT_sem'].loc[hour]*result.params[2] + \n",
    "                                            test_data_copy['LMP_DA'].loc[hour]*result.params[1] + \n",
    "                                            result.params[0])\n",
    "            for predictor in result.pvalues.index:\n",
    "                pvalues[predictor].append(result.pvalues.loc[predictor])\n",
    "        sklearn_PE_list.append(pe(test_data_copy['fitted RT (sklearn)'], test_data_copy['LMP_RT']).mean())\n",
    "    sklearn_PE_array[i] = np.array(sklearn_PE_list).mean()\n",
    "    print('{}%'.format(10*i))\n",
    "print('MAPE: {}'.format(sklearn_PE_array.mean()))\n",
    "means_dict(pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions\n",
    "- Why does the warning come up when result is accessed?\n",
    "- Why are p-values so high? -> evaluate each regression separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "10%\n",
      "20%\n",
      "30%\n",
      "40%\n",
      "50%\n",
      "60%\n",
      "70%\n",
      "80%\n",
      "90%\n",
      "p-values:\n",
      "\tRT_sem: 0.01068739506079447\n",
      "\tDA_sem: 0.061292946442669444\n",
      "\tLMP_DA: 0.3677988146640826\n",
      "\tLoad: 0.3585934531989948\n",
      "\tWind: 0.07302364708295592\n"
     ]
    }
   ],
   "source": [
    "# calculate p-values for each predictor - forward selection\n",
    "\n",
    "# np.seterr(divide='ignore',invalid='ignore') # ignore errors for n=100\n",
    "n = 100\n",
    "RTsem_model = []\n",
    "DA_model = []\n",
    "load_model = []\n",
    "DAsem_model = []\n",
    "wind_model = []\n",
    "for i in range(n):\n",
    "    for j in range(1,13):\n",
    "        by_month = DART_gen_2018[DART_gen_2018['Month']==j]\n",
    "\n",
    "        train, test = train_test_split(by_month, test_size=0.33)\n",
    "\n",
    "        train_data = train.groupby('Local Time')[['LMP_RT','LMP_DA','Load','Wind']].mean()\n",
    "        train_data['RT_sem'] = train.groupby('Local Time')['LMP_RT'].sem()\n",
    "        train_data['DA_sem'] = train.groupby('Local Time')['LMP_DA'].sem()        \n",
    "\n",
    "        test_data = test.groupby('Local Time')[['LMP_RT','LMP_DA','Load','Wind']].mean()\n",
    "        test_data['RT_sem'] = test.groupby('Local Time')['LMP_RT'].sem()\n",
    "        test_data['DA_sem'] = test.groupby('Local Time')['LMP_DA'].sem() \n",
    "        test_data_copy = test_data.copy()\n",
    "        test_data_copy['fitted RT (sklearn)'] = np.zeros(test_data_copy.index.shape[0])\n",
    "        branch_dfs = sklearn_clusters(train_data, test_data)\n",
    "        for cluster in branch_dfs:\n",
    "            result = smf.ols(formula=\"LMP_RT ~ RT_sem\", data=cluster).fit()\n",
    "            RTsem_model.append(result.pvalues[0])\n",
    "            result = smf.ols(formula=\"LMP_RT ~ LMP_DA\", data=cluster).fit()\n",
    "            DA_model.append(result.pvalues[0])\n",
    "            result = smf.ols(formula=\"LMP_RT ~ Load\", data=cluster).fit()\n",
    "            load_model.append(result.pvalues[0])\n",
    "            result = smf.ols(formula=\"LMP_RT ~ DA_sem\", data=cluster).fit()\n",
    "            DAsem_model.append(result.pvalues[0])\n",
    "            result = smf.ols(formula=\"LMP_RT ~ Wind\", data=cluster).fit()\n",
    "            wind_model.append(result.pvalues[0])\n",
    "\n",
    "    if i%(10)==0:\n",
    "        print('{}%'.format(i))\n",
    "            \n",
    "print('p-values:')\n",
    "print('\\tRT_sem: {}'.format(np.nanmean(RTsem_model).mean()))\n",
    "print('\\tDA_sem: {}'.format(np.nanmean(DAsem_model).mean()))\n",
    "print('\\tLMP_DA: {}'.format(np.nanmean(DA_model).mean()))\n",
    "print('\\tLoad: {}'.format(np.nanmean(load_model).mean()))\n",
    "print('\\tWind: {}'.format(np.nanmean(wind_model).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### p-values test\n",
    "still many warnings, but results were (for n = 100 * 12):\n",
    "\n",
    "|factor |result +- sem  |\n",
    "|-------|---------------|\n",
    "|RT_sem | 0.011 +- 0.001|\n",
    "|DA_sem | 0.061 +- 0.002|\n",
    "|LMP_DA | 0.368 +- 0.003|\n",
    "|Load   | 0.356 +- 0.003|\n",
    "|Wind   | 0.073 +- 0.002|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "10%\n",
      "20%\n",
      "30%\n",
      "40%\n",
      "50%\n",
      "60%\n",
      "70%\n",
      "80%\n",
      "90%\n",
      "MAPE: 7.191024319226516\n",
      "MAPE for Adjusted R^2 > 0.8: 7.040845958901403\n",
      "53.333333333333336% of months had Adjusted R^2 > 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2329d2f7da0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I'll ignore warnings for the following test\n",
    "\n",
    "np.seterr(divide='ignore',invalid='ignore')\n",
    "n = 10\n",
    "sklearn_PE_array = np.zeros(n)\n",
    "best_PE_array = np.zeros(n)\n",
    "all_R2adj = []\n",
    "all_PE = []\n",
    "k = 0\n",
    "r = 0.8\n",
    "for i in range(n):\n",
    "    sklearn_PE_list = []\n",
    "    best_PE_list = []\n",
    "    for j in range(1,13):\n",
    "        by_month = DART_gen_2018[DART_gen_2018['Month']==j]\n",
    "\n",
    "        train, test = train_test_split(by_month, test_size=0.33)\n",
    "\n",
    "        train_data = train.groupby('Local Time')[['LMP_RT','LMP_DA','Load','Wind']].mean()\n",
    "        train_data['RT_sem'] = train.groupby('Local Time')['LMP_RT'].sem()\n",
    "        train_data['DA_sem'] = train.groupby('Local Time')['LMP_DA'].sem()        \n",
    "\n",
    "        test_data = test.groupby('Local Time')[['LMP_RT','LMP_DA','Load','Wind']].mean()\n",
    "        test_data['RT_sem'] = test.groupby('Local Time')['LMP_RT'].sem()\n",
    "        test_data['DA_sem'] = test.groupby('Local Time')['LMP_DA'].sem() \n",
    "        test_data_copy = test_data.copy()\n",
    "        test_data_copy['fitted RT (sklearn)'] = np.zeros(test_data_copy.index.shape[0])\n",
    "        branch_dfs = sklearn_clusters(train_data, test_data)\n",
    "        month_R2adj = []\n",
    "        for cluster in branch_dfs:\n",
    "            result = smf.ols(formula=\"LMP_RT ~ LMP_DA + RT_sem + DA_sem + Load + Wind\", data=cluster).fit()\n",
    "            month_R2adj.append(result.rsquared_adj)\n",
    "            for hour in cluster.index:\n",
    "                test_data_copy['fitted RT (sklearn)'].loc[hour] = ( \n",
    "                                            test_data_copy['Wind'].loc[hour]*result.params[5] + \n",
    "                                            test_data_copy['Load'].loc[hour]*result.params[4] + \n",
    "                                            test_data_copy['DA_sem'].loc[hour]*result.params[3] + \n",
    "                                            test_data_copy['RT_sem'].loc[hour]*result.params[2] + \n",
    "                                            test_data_copy['LMP_DA'].loc[hour]*result.params[1] + \n",
    "                                            result.params[0])\n",
    "        \n",
    "        PE = pe(test_data_copy['fitted RT (sklearn)'], test_data_copy['LMP_RT']).mean()\n",
    "        \n",
    "        if np.nanmean(np.array(month_R2adj)) > r:\n",
    "            best_PE_list.append(PE)\n",
    "            k += 1\n",
    "        sklearn_PE_list.append(PE)\n",
    "        \n",
    "        all_R2adj.append(np.nanmean(np.array(month_R2adj)))\n",
    "        all_PE.append(PE)\n",
    "        \n",
    "    sklearn_PE_array[i] = np.array(sklearn_PE_list).mean()\n",
    "    best_PE_array[i] = np.array(best_PE_list).mean()\n",
    "\n",
    "    print('{}%'.format(10*i))\n",
    "print('MAPE: {}'.format(sklearn_PE_array.mean()))\n",
    "print('MAPE for Adjusted R^2 > {}: {}'.format(r, best_PE_array.mean()))\n",
    "print('{}% of months had Adjusted R^2 > {}'.format(100*k/(12*n), r))\n",
    "plt.plot(np.array(all_R2adj), np.array(all_PE), 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
